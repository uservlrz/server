// index.js - Servidor Node.js otimizado para Vercel e ambiente local com Vercel Blob
const express = require('express');
const multer = require('multer');
const cors = require('cors');
const path = require('path');
const fs = require('fs');
const { OpenAI } = require('openai');
require('dotenv').config();

// Importar utilit√°rios de processamento de PDF
const { parsePdf } = require('./utils/pdfParser');
const { validatePdf, repairPdf } = require('./utils/pdfValidator');
const { isPdfEncrypted, attemptPdfDecryption, isVercelEnvironment } = require('./utils/pdfDecryptor');
const { splitPDF, cleanupTempFiles } = require('./utils/pdfSplitter');
const { processOcr } = require('./utils/ocrService');
// ADI√á√ÉO: Importar o gerenciador do Vercel Blob
const { 
  shouldUseBlob, 
  processLargePdfWithBlob, 
  validatePdfForBlob 
} = require('./utils/blobHandler');

const app = express();
const PORT = process.env.PORT || 5000;

// Verificar ambiente
const isVercel = isVercelEnvironment();
console.log(`Ambiente: ${isVercel ? 'Vercel' : 'Local'}`);

// Configura√ß√£o CORS melhorada para permitir acesso do frontend
app.use(cors({
  origin: '*', // Permite qualquer origem - ajuste para produ√ß√£o se necess√°rio
  methods: ['GET', 'POST', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization'],
  credentials: true,
  maxAge: 86400 // 24 horas em segundos
}));

// Middleware para parsing JSON com limite aumentado
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Verificar se API Keys existem
if (!process.env.OPENAI_API_KEY) {
  console.error('ERRO: Chave da API da OpenAI n√£o encontrada! Verifique as vari√°veis de ambiente.');
}

if (!process.env.OCR_API_KEY || process.env.OCR_API_KEY === 'helloworld') {
  console.warn('AVISO: Usando chave de API OCR padr√£o. Obtenha uma chave em ocr.space para melhor funcionamento.');
}

// Verificar se Vercel Blob est√° configurado (apenas para logs)
if (isVercel && !process.env.BLOB_READ_WRITE_TOKEN) {
  console.warn('AVISO: BLOB_READ_WRITE_TOKEN n√£o encontrado. Vercel Blob pode n√£o funcionar.');
}

// Configurar OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Configurar diret√≥rio de uploads
const uploadDir = isVercel ? '/tmp' : 'uploads';

// Criar diret√≥rio de uploads apenas para desenvolvimento local
try {
  if (!isVercel && !fs.existsSync(uploadDir)) {
    fs.mkdirSync(uploadDir, { recursive: true });
    console.log(`Diret√≥rio de uploads criado: ${uploadDir}`);
  }
} catch (err) {
  console.error(`Erro ao criar diret√≥rio de uploads: ${err.message}`);
}

// Configura√ß√£o do Multer para upload de arquivos com limites din√¢micos
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    cb(null, uploadDir);
  },
  filename: function (req, file, cb) {
    cb(null, Date.now() + '-' + file.originalname);
  }
});

const upload = multer({ 
  storage: storage,
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'application/pdf') {
      cb(null, true);
    } else {
      cb(new Error('Apenas arquivos PDF s√£o permitidos'), false);
    }
  },
  limits: {
    // Limites din√¢micos baseados no ambiente
    fileSize: isVercel ? 4 * 1024 * 1024 : 100 * 1024 * 1024 // 4MB Vercel, 100MB local
  }
});

// Middleware para verificar tamanho antes do upload
app.use('/api/upload', (req, res, next) => {
  const contentLength = parseInt(req.headers['content-length'] || '0');
  const maxSize = isVercel ? 4 * 1024 * 1024 : 100 * 1024 * 1024;
  
  if (contentLength > maxSize) {
    const sizeMB = (contentLength / 1024 / 1024).toFixed(2);
    const maxSizeMB = (maxSize / 1024 / 1024).toFixed(0);
    
    return res.status(413).json({ 
      message: `Arquivo muito grande (${sizeMB}MB). Use a rota /api/upload-large para arquivos maiores que ${maxSizeMB}MB.`,
      currentSize: sizeMB + 'MB',
      maxSize: maxSizeMB + 'MB',
      environment: isVercel ? 'vercel' : 'local',
      shouldUseLargeUpload: true
    });
  }
  next();
});

// Nova fun√ß√£o para extrair o nome do paciente via OCR
async function extractPatientNameViaOcr(filePath) {
  try {
    console.log("Extraindo nome do paciente via OCR (fallback)...");
    
    // Executar OCR no arquivo
    const ocrResults = await processOcr(filePath);
    
    if (!ocrResults || ocrResults.length === 0 || !ocrResults[0].text) {
      throw new Error("OCR n√£o retornou resultados utiliz√°veis");
    }
    
    // Extrair nome do paciente do texto OCR
    const initialOcrText = ocrResults[0].text.slice(0, 3000);
    
    // Tentar regex primeiro
    const regexPatterns = [
      /Paciente\s*[:]\s*([A-Z√Ä-√ö√á\s]+)/i,
      /Nome do Paciente\s*[:]\s*([A-Z√Ä-√ö√á\s]+)/i,
      /Paciente[:]?\s+([A-Z√Ä-√ö√á][A-Z√Ä-√ö√áa-z√†-√∫√ß\s]+)/,
      /Nome[:]?\s+([A-Z√Ä-√ö√á][A-Z√Ä-√ö√áa-z√†-√∫√ß\s]+)/
    ];
    
    for (const pattern of regexPatterns) {
      const match = initialOcrText.match(pattern);
      if (match && match[1]) {
        const extractedName = match[1].trim();
        if (extractedName.length > 3 && extractedName.includes(' ')) {
          console.log(`Nome extra√≠do via OCR regex: ${extractedName}`);
          return extractedName;
        }
      }
    }
    
    // Se regex falhar, usar GPT no resultado OCR
    console.log("Usando GPT para extrair o nome do paciente do texto OCR...");
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { 
          role: 'system', 
          content: 'Voc√™ √© um extrator preciso de informa√ß√µes de documentos m√©dicos. Voc√™ extrai apenas o nome completo do paciente sem adicionar nenhuma informa√ß√£o extra.'
        },
        { 
          role: 'user', 
          content: `Extraia APENAS o nome completo do paciente do seguinte trecho de um exame laboratorial processado por OCR. 
          Retorne SOMENTE o nome completo, sem nenhum texto adicional, prefixo ou sufixo.
          
          Texto para an√°lise:
          ${initialOcrText}` 
        }
      ],
      max_tokens: 100,
      temperature: 0.1,
    });
    
    const patientName = response.choices[0].message.content.trim();
    console.log(`Nome extra√≠do via OCR + GPT: ${patientName}`);
    return patientName;
  } catch (error) {
    console.error("Erro ao extrair nome via OCR:", error);
    return "Nome do Paciente n√£o identificado";
  }
}

// Fun√ß√£o para extrair o nome do paciente do PDF com fallback para OCR
async function extractPatientName(pages, filePath) {
  try {
    // Se n√£o temos p√°ginas ou texto, recorrer ao OCR imediatamente
    if (!pages || !pages.length || !pages[0].text) {
      console.log("Sem texto extra√≠vel, recorrendo ao OCR para nome do paciente...");
      return await extractPatientNameViaOcr(filePath);
    }
    
    // Pegamos apenas o in√≠cio do documento para encontrar o nome do paciente
    const initialText = pages[0].text.slice(0, 3000);
    
    // Primeiro, tenta extrair o nome usando express√µes regulares (mais r√°pido e econ√¥mico)
    const regexPatterns = [
      /Paciente\s*[:]\s*([A-Z√Ä-√ö√á\s]+)/i,              // Padr√£o comum em laudos m√©dicos
      /Nome do Paciente\s*[:]\s*([A-Z√Ä-√ö√á\s]+)/i,      // Outra varia√ß√£o comum
      /Paciente[:]?\s+([A-Z√Ä-√ö√á][A-Z√Ä-√ö√áa-z√†-√∫√ß\s]+)/, // Formato mais gen√©rico
      /Nome[:]?\s+([A-Z√Ä-√ö√á][A-Z√Ä-√ö√áa-z√†-√∫√ß\s]+)/      // Busca por "Nome:"
    ];
    
    for (const pattern of regexPatterns) {
      const match = initialText.match(pattern);
      if (match && match[1]) {
        const extractedName = match[1].trim();
        if (extractedName.length > 3 && extractedName.includes(' ')) {
          console.log(`Nome extra√≠do via regex: ${extractedName}`);
          return extractedName;
        }
      }
    }
    
    // Se n√£o conseguiu extrair com regex, usa o GPT
    console.log("Usando GPT para extrair o nome do paciente...");
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { 
          role: 'system', 
          content: 'Voc√™ √© um extrator preciso de informa√ß√µes de documentos m√©dicos. Voc√™ extrai apenas o nome completo do paciente sem adicionar nenhuma informa√ß√£o extra.'
        },
        { 
          role: 'user', 
          content: `Extraia APENAS o nome completo do paciente do seguinte trecho de um exame laboratorial. 
          Retorne SOMENTE o nome completo, sem nenhum texto adicional, prefixo ou sufixo.
          Se voc√™ n√£o conseguir identificar o nome com certeza, retorne "FALLBACK_TO_OCR".
          
          Texto para an√°lise:
          ${initialText}` 
        }
      ],
      max_tokens: 100,
      temperature: 0.1,
    });
    
    const patientName = response.choices[0].message.content.trim();
    
    // Se o GPT n√£o conseguiu extrair o nome com confian√ßa, tentar OCR como fallback
    if (patientName === "FALLBACK_TO_OCR" || 
        patientName === "Nome do Paciente n√£o identificado" || 
        patientName.length < 4 || 
        !patientName.includes(" ")) {
      console.log("GPT n√£o conseguiu extrair o nome com confian√ßa. Tentando OCR como fallback...");
      return await extractPatientNameViaOcr(filePath);
    }
    
    return patientName;
  } catch (error) {
    console.error('Erro ao extrair nome do paciente:', error);
    
    // Se ocorrer um erro, tentamos OCR como √∫ltimo recurso
    try {
      console.log("Erro na extra√ß√£o normal, tentando OCR como fallback...");
      return await extractPatientNameViaOcr(filePath);
    } catch (ocrError) {
      console.error('Erro ao extrair nome via OCR:', ocrError);
      return 'Nome do Paciente n√£o identificado';
    }
  }
}

// Fun√ß√£o para gerar resumos com GPT-3.5 - vers√£o simplificada mantendo a ordem original
async function generateSummaries(pages, patientName) {
  const summaries = [];

  function splitTextIntoChunks(text, maxTokens = 3000) {
    const chunkSize = maxTokens * 4;
    const chunks = [];
    
    for (let i = 0; i < text.length; i += chunkSize) {
      chunks.push(text.slice(i, i + chunkSize));
    }
    
    return chunks;
  }

  // Manter um registro global dos exames j√° extra√≠dos entre todas as p√°ginas
  const seenExams = new Set();
  let allResults = [];

  for (const page of pages) {
    try {
      const textChunks = splitTextIntoChunks(page.text);
      let pageResults = [];
      
      for (const chunk of textChunks) {
        // Prompt espec√≠fico para extrair apenas refer√™ncias num√©ricas com valores
        const prompt = `Analise o seguinte texto de um documento de exames laboratoriais e extraia as informa√ß√µes conforme estas instru√ß√µes EXATAS:

1. EXTRAIA APENAS:
   - Nome do exame (exatamente como aparece no documento)
   - Valor num√©rico do resultado (sem unidades de medida). Geralmente vem depois da palavra "Resultado" 
   - Intervalo de refer√™ncia (somente os valores num√©ricos m√≠nimo e m√°ximo)

2. FORMATO EXATO para cada linha:
   "Nome do Exame: Valor | VR: M√≠nimo - M√°ximo"

3. APENAS para resultados com percentual E valor absoluto, use:
   "Nome do Exame: Percentual % / Valor absoluto | VR: M√≠nimo - M√°ximo"

4. REGRAS OBRIGAT√ìRIAS:
   - NUNCA adicione unidades de medida junto com os valores num√©ricos
   - N√ÉO use h√≠fen ou outro caractere no in√≠cio da linha
   - SEMPRE marque resultados ALTERADOS (fora do VR) adicionando *** AP√ìS o valor num√©rico
   - NUNCA adicione texto explicativo ou notas adicionais
   - NUNCA adicione m√©todos ou informa√ß√µes sobre a t√©cnica utilizada
   - MANTENHA os n√∫meros EXATAMENTE como aparecem no texto (n√£o arredonde)
   - Para valores com sinal menor ou maior (ex: "<0,5"), mantenha exatamente como aparece
   - Quando o valor de refer√™ncia √© "at√© X" ou "menor que X", use o formato "0 - X"
   - Para intervalos de refer√™ncia baseados em idade/sexo, escolha o mais apropriado ou use o intervalo geral

5. EXAMES PRIORIT√ÅRIOS (sempre extrair se presentes):
   - Perfil Lip√≠dico: Colesterol Total, HDL, LDL, VLDL, Triglicer√≠deos
   - Horm√¥nios: Testosterona Total, SHBG, Testosterona Livre, Testosterona Biodispon√≠vel, DHT, Cortisol
   - Metab√≥licos: Glicose, Insulina, Hemoglobina Glicada, HOMA-IR
   - Fun√ß√£o Hep√°tica: TGO/AST, TGP/ALT, GGT, Fosfatase Alcalina, Bilirrubina
   - Fun√ß√£o Renal: Ureia, Creatinina, Taxa de Filtra√ß√£o Glomerular, √Åcido √örico
   - Vitaminas e Minerais: Ferro, Ferritina, Vitamina D, Vitamina B12, Zinco, Magn√©sio, S√≥dio, Pot√°ssio, C√°lcio
   - Hematol√≥gicos: Hemoglobina, Hemat√≥crito, Leuc√≥citos, Plaquetas
   - Outros: TSH, T4 Livre, T3, Prote√≠na C Reativa, PSA

6. EXEMPLOS CORRETOS:
   - "Glicose: 95 | VR: 70 - 99"
   - "Colesterol Total: 220*** | VR: 0 - 190"
   - "Hemoglobina: 13,5 | VR: 13,0 - 18,0"
   - "Neutr√≥filos: 65 % / 3900 | VR: 40 - 70"
   - "TSH: <0,01*** | VR: 0,27 - 4,20"

Texto para an√°lise:
${chunk}`;
        
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { 
              role: 'system', 
              content: 'Voc√™ √© um extrator especializado de resultados laboratoriais com extrema precis√£o. Extraia APENAS a primeira ocorr√™ncia de cada exame, mantendo a ordem exata em que aparecem no texto. N√£o adicione informa√ß√µes extras ou explica√ß√µes.'
            },
            { role: 'user', content: prompt }
          ],
          max_tokens: 1000,
          temperature: 0.1,
        });
        
        // Processar a resposta linha por linha
        const extractedLines = response.choices[0].message.content.trim().split('\n');
        
        extractedLines.forEach(line => {
          // Ignorar linhas vazias
          if (!line.trim()) return;
          
          // Remover h√≠fens no in√≠cio e espa√ßos extras
          line = line.replace(/^-\s*/, '').trim();
          
          // Extrair o nome do exame para verificar duplicatas
          const match = line.match(/^([^:]+):/);
          if (match) {
            const examName = match[1].trim().toLowerCase();
            
            // Verificar variantes comuns do mesmo exame (ex: tgo, ast, tgp, alt)
            let examKey = examName;
            if (/\b(tgo|ast|aspartato)\b/.test(examName)) examKey = 'tgo';
            else if (/\b(tgp|alt|alanina)\b/.test(examName)) examKey = 'tgp';
            else if (/\b(gamma|gama|ggt)\b/.test(examName)) examKey = 'ggt';
            else if (/\b(glicose|glicemia)\b/.test(examName)) examKey = 'glicose';
            
            // Apenas adicionar se n√£o vimos este exame antes
            if (!seenExams.has(examKey)) {
              seenExams.add(examKey);
              pageResults.push(line);
            }
          } else {
            // Se n√£o conseguir extrair o nome, adicionar linha mesmo assim
            pageResults.push(line);
          }
        });
      }
      
      // Adicionar resultados desta p√°gina ao acumulado global, mantendo a ordem
      allResults = [...allResults, ...pageResults];
      
    } catch (error) {
      console.error(`Erro ao gerar resumo para a p√°gina ${page.page}:`, error);
    }
  }
  
  // Montar o resumo final com todos os resultados coletados
  let finalContent = `Paciente: ${patientName}\n\n` + allResults.join('\n');
  
  // Retornar como um √∫nico resumo
  return [{
    page: 1,
    content: finalContent
  }];
}

// Fun√ß√£o para remover duplicatas nos resultados
function removeDuplicates(content) {
  // Preservar a primeira linha com o nome do paciente
  const lines = content.split('\n');
  const patientLine = lines[0]; // Linha com "Paciente: Nome do Paciente"
  
  // Processar as linhas de exames (come√ßando da linha 2, ap√≥s o cabe√ßalho e a linha em branco)
  const examLines = lines.slice(2);
  const uniqueLines = [];
  const seenExams = new Set();
  
  for (const line of examLines) {
    // Extrair o nome do exame (assumindo formato "NOME DO EXAME: resultado")
    const match = line.match(/^([^:]+):/);
    if (match) {
      const examName = match[1].trim();
      if (!seenExams.has(examName)) {
        seenExams.add(examName);
        uniqueLines.push(line);
      }
    } else {
      // Se n√£o conseguir extrair o nome do exame, inclua a linha de qualquer forma
      uniqueLines.push(line);
    }
  }
  
  // Reconstruir o conte√∫do: linha do paciente + linha em branco + exames √∫nicos
  return `${patientLine}\n\n${uniqueLines.join('\n')}`;
}

// NOVA FUN√á√ÉO: Processamento principal de PDF (extra√≠da para reutiliza√ß√£o)
async function processPdfMain(pdfBuffer, filename, filePath = null) {
  let tempFiles = [];
  let patientName = 'Nome do Paciente n√£o identificado';
  let extractionMethod = 'normal';
  let processingResults = [];
  
  try {
    console.log(`Processando PDF: ${filename}, tamanho: ${(pdfBuffer.length / 1024 / 1024).toFixed(2)}MB`);
    
    // Passo 1: Validar o PDF
    console.log("Validando o PDF...");
    
    // Passo 2: Verificar se o PDF est√° criptografado
    const isEncrypted = await isPdfEncrypted(pdfBuffer);
    console.log(`PDF est√° criptografado? ${isEncrypted ? 'Sim' : 'N√£o'}`);
    
    let pdfParts = null;
    let finalText = null;
    
    // ADI√á√ÉO: Tentar OCR primeiro se o PDF estiver criptografado
    if (isEncrypted) {
      try {
        console.log("Tentativa OCR: Processando PDF protegido via API OCR...");
        
        // Para usar OCR, precisamos salvar temporariamente
        let tempPath = null;
        if (filePath) {
          tempPath = filePath;
        } else {
          tempPath = `/tmp/${Date.now()}-${filename}`;
          fs.writeFileSync(tempPath, pdfBuffer);
          tempFiles.push(tempPath);
        }
        
        const ocrResults = await processOcr(tempPath);
        
        if (ocrResults && ocrResults.length > 0 && ocrResults[0].text) {
          console.log("OCR via API bem-sucedido!");
          finalText = ocrResults;
          extractionMethod = 'ocr_api';
          
          // Extrair nome do paciente do texto OCR
          patientName = await extractPatientName(ocrResults, tempPath);
          console.log(`Nome do paciente identificado via OCR: ${patientName}`);
          
          // Preparar os resumos
          const summaries = await generateSummaries(finalText, patientName);
          
          // Processar os resultados para remover duplicatas
          const processedSummaries = summaries.map(summary => ({
            ...summary,
            content: removeDuplicates(summary.content)
          }));
          
          return {
            summaries: processedSummaries,
            patientName: patientName,
            extractionMethod: extractionMethod,
            processingDetails: processingResults.length > 0 ? processingResults : undefined
          };
        } else {
          console.log("OCR via API n√£o retornou texto utiliz√°vel, tentando outros m√©todos");
          processingResults.push({
            method: 'ocr_api',
            success: false,
            error: 'Sem texto reconhecido'
          });
        }
      } catch (ocrError) {
        console.error("Erro no processamento OCR via API:", ocrError);
        processingResults.push({
          method: 'ocr_api',
          success: false,
          error: ocrError.message
        });
      }
    }
    
    // Se OCR falhou ou n√£o foi utilizado, continuar com fluxo normal
    
    // Processando o PDF de acordo com suas caracter√≠sticas
    if (isEncrypted && !finalText) {
      // Se o PDF estiver criptografado, tentar remover a prote√ß√£o
      console.log("PDF est√° criptografado, tentando remover prote√ß√£o...");
      const decryptResult = await attemptPdfDecryption(filePath || pdfBuffer);
      
      if (decryptResult.success) {
        console.log("Prote√ß√£o removida com sucesso, processando PDF desprotegido...");
        tempFiles.push(decryptResult.decryptedPath);
        extractionMethod = 'desprotegido';
        
        // Usar o arquivo desprotegido para os pr√≥ximos passos
        const decryptedBuffer = fs.readFileSync(decryptResult.decryptedPath);
        pdfParts = await splitPDF(decryptedBuffer);
      } else {
        console.log("N√£o foi poss√≠vel remover a prote√ß√£o, tentando reparar...");
        processingResults.push({
          method: 'desproteger',
          success: false,
          error: decryptResult.error
        });
        
        // Tentar reparar o PDF
        const repairResult = await repairPdf(filePath || pdfBuffer);
        
        if (repairResult.success) {
          console.log("PDF reparado com sucesso, processando...");
          tempFiles.push(repairResult.repairedPath);
          extractionMethod = 'reparado';
          
          // Usar o arquivo reparado para os pr√≥ximos passos
          const repairedBuffer = fs.readFileSync(repairResult.repairedPath);
          pdfParts = await splitPDF(repairedBuffer);
        } else {
          // Se n√£o conseguimos desproteger nem reparar, tentar com o arquivo original
          console.log("N√£o foi poss√≠vel reparar, tentando processar o arquivo original...");
          pdfParts = await splitPDF(pdfBuffer);
        }
      }
    } else if (!isEncrypted) {
      // Se o PDF n√£o est√° criptografado, dividir em partes normalmente
      console.log("Dividindo o PDF em partes menores...");
      pdfParts = await splitPDF(pdfBuffer);
    }
    
    // Se ainda n√£o temos um resultado final do OCR, continuamos o processamento normal
    if (!finalText) {
      // Se n√£o conseguimos dividir o PDF, usar o arquivo original como uma √∫nica parte
      if (!pdfParts || pdfParts.length === 0) {
        console.log("Falha ao dividir o PDF, usando como parte √∫nica");
        pdfParts = [pdfBuffer];
        if (extractionMethod === 'normal') {
          extractionMethod = 'falha_divisao';
        }
      } else {
        console.log(`PDF dividido em ${pdfParts.length} partes`);
      }
      
      // Extrair texto da primeira parte para obter o nome do paciente
      console.log("Extraindo informa√ß√µes do paciente...");
      const initialPages = await parsePdf(pdfParts[0]);
      
      // Usar a nova fun√ß√£o de extra√ß√£o de nome com fallback para OCR
      const tempPathForName = filePath || (tempFiles.length > 0 ? tempFiles[0] : null);
      patientName = await extractPatientName(initialPages, tempPathForName);
      console.log(`Nome do paciente identificado: ${patientName}`);
      
      const allSummaries = [];
      
      // Processar cada parte do PDF
      for (let i = 0; i < pdfParts.length; i++) {
        try {
          console.log(`Processando parte ${i+1}/${pdfParts.length}...`);
          const partBuffer = pdfParts[i];
          
          // Extrair texto desta parte
          const pages = await parsePdf(partBuffer);
          
          // Gerar resumos para esta parte, incluindo o nome do paciente
          const summaries = await generateSummaries(pages, patientName);
          
          // Adicionar os resumos ao array geral
          allSummaries.push(...summaries);
        } catch (partError) {
          console.error(`Erro ao processar a parte ${i+1}:`, partError);
          allSummaries.push({
            page: `Parte ${i+1}`,
            content: `Paciente: ${patientName}\n\nErro ao processar esta parte do documento.`
          });
        }
      }
      
      // Processar os resultados para remover duplicatas
      for (let i = 0; i < allSummaries.length; i++) {
        allSummaries[i].content = removeDuplicates(allSummaries[i].content);
      }
      
      return {
        summaries: allSummaries,
        patientName: patientName,
        extractionMethod: extractionMethod,
        processingDetails: processingResults.length > 0 ? processingResults : undefined
      };
    }
    
  } catch (error) {
    console.error('Erro no processamento:', error);
    throw error;
  } finally {
    // Limpar arquivos tempor√°rios
    tempFiles.forEach(tempFile => {
      try {
        if (fs.existsSync(tempFile)) {
          fs.unlinkSync(tempFile);
          console.log(`Arquivo tempor√°rio removido: ${tempFile}`);
        }
      } catch (cleanupError) {
        console.error(`Erro ao remover arquivo tempor√°rio ${tempFile}:`, cleanupError);
      }
    });
  }
}

// Rota para a p√°gina inicial
app.get('/', (req, res) => {
  res.send(`
    <!DOCTYPE html>
    <html lang="pt-br">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>API de Processamento de Exames</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 20px;
                color: #333;
                max-width: 800px;
                margin: 0 auto;
            }
            h1 {
                color: #2c3e50;
                border-bottom: 2px solid #3498db;
                padding-bottom: 10px;
            }
            h2 {
                color: #2980b9;
            }
            .endpoint {
                background-color: #f8f9fa;
                border-left: 4px solid #3498db;
                padding: 10px 15px;
                margin: 15px 0;
            }
            .method {
                font-weight: bold;
                color: #e74c3c;
            }
            .path {
                font-family: monospace;
                background-color: #eee;
                padding: 2px 5px;
                border-radius: 3px;
            }
            .description {
                margin-top: 5px;
            }
            footer {
                margin-top: 30px;
                border-top: 1px solid #eee;
                padding-top: 10px;
                font-size: 0.8em;
                color: #7f8c8d;
            }
            .blob-info {
                background: #e7f3ff;
                padding: 15px;
                border-radius: 5px;
                margin: 20px 0;
            }
        </style>
    </head>
    <body>
        <h1>API de Processamento de Exames</h1>
        <p>Esta √© a API do sistema de processamento de laudos laboratoriais. Esta API fornece endpoints para processar arquivos PDF de exames m√©dicos e extrair informa√ß√µes relevantes.</p>
        
        <h2>Endpoints Dispon√≠veis</h2>
        
        <div class="endpoint">
            <div><span class="method">GET</span> <span class="path">/api/health</span></div>
            <div class="description">Verifica se a API est√° funcionando corretamente.</div>
        </div>
        
        <div class="endpoint">
            <div><span class="method">POST</span> <span class="path">/api/upload</span></div>
            <div class="description">Recebe um arquivo PDF de exames m√©dicos (at√© 4MB) e retorna um resumo estruturado dos dados extra√≠dos.</div>
        </div>
        
        <div class="endpoint">
            <div><span class="method">POST</span> <span class="path">/api/upload-large</span></div>
            <div class="description">Processa arquivos PDF grandes (at√© 100MB) usando Vercel Blob storage.</div>
        </div>
        
        <div class="blob-info">
            <h3>üí° Suporte para Arquivos Grandes</h3>
            <p><strong>Arquivos at√© 4MB:</strong> Use /api/upload (upload direto)</p>
            <p><strong>Arquivos maiores que 4MB:</strong> Use /api/upload-large (via Vercel Blob)</p>
            <p><strong>Limite m√°ximo:</strong> 100MB por arquivo</p>
        </div>
        
        <h2>Como Usar</h2>
        <p>Esta API deve ser consumida pelo frontend da aplica√ß√£o. N√£o √© destinada para uso direto no navegador.</p>
        
        <footer>
            &copy; 2025 Instituto Paulo Godoi - API de Processamento de Exames
            <p>Ambiente: ${isVercel ? 'Vercel (Produ√ß√£o)' : 'Local (Desenvolvimento)'}</p>
            <p>Blob Storage: ${process.env.BLOB_READ_WRITE_TOKEN ? 'Configurado' : 'N√£o configurado'}</p>
        </footer>
    </body>
    </html>
  `);
});

// Rota para verifica√ß√£o de sa√∫de da API
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    env: isVercel ? 'vercel' : 'local',
    timestamp: new Date().toISOString(),
    blobSupport: !!process.env.BLOB_READ_WRITE_TOKEN,
    limits: {
      smallFiles: '4MB (upload direto)',
      largeFiles: '100MB (via Blob)'
    }
  });
});

// Rota para upload de PDFs pequenos (m√©todo original)
app.post('/api/upload', upload.single('pdf'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'Nenhum arquivo foi enviado' });
    }

    const filePath = req.file.path;
    const fileSize = fs.statSync(filePath).size;
    const fileSizeMB = fileSize / (1024 * 1024);
    
    console.log(`Arquivo recebido via upload direto: ${req.file.originalname} (${fileSizeMB.toFixed(2)}MB)`);
    
    // Lista para armazenar caminhos de arquivos tempor√°rios para limpeza
    let tempFiles = [];
    let patientName = 'Nome do Paciente n√£o identificado';
    let extractionMethod = 'normal';
    let errorDetails = null;
    
    try {
      // Ler o arquivo PDF
      const pdfBuffer = fs.readFileSync(filePath);
      console.log(`Arquivo lido com sucesso, tamanho: ${pdfBuffer.length} bytes`);
      
      // Passo 1: Validar o PDF
      console.log("Validando o PDF...");
      const validationResult = await validatePdf(filePath);
      console.log("Resultado da valida√ß√£o:", validationResult.message);
      
      // Passo 2: Verificar se o PDF est√° criptografado
      const isEncrypted = await isPdfEncrypted(filePath);
      console.log(`PDF est√° criptografado? ${isEncrypted ? 'Sim' : 'N√£o'}`);
      
      // Array para armazenar os resultados das tentativas
      let processingResults = [];
      let pdfParts = null;
      let finalText = null;
      
      // ADI√á√ÉO: Tentar OCR primeiro se o PDF estiver criptografado
      if (isEncrypted) {
        try {
          console.log("Tentativa OCR: Processando PDF protegido via API OCR...");
          
          // Executar OCR usando API externa
          const ocrResults = await processOcr(filePath);
          
          if (ocrResults && ocrResults.length > 0 && ocrResults[0].text) {
            console.log("OCR via API bem-sucedido!");
            finalText = ocrResults;
            extractionMethod = 'ocr_api';
            
            // Extrair nome do paciente do texto OCR
            patientName = await extractPatientName(ocrResults, filePath);
            console.log(`Nome do paciente identificado via OCR: ${patientName}`);
            
            // Preparar os resumos
            const summaries = await generateSummaries(finalText, patientName);
            
            // Processar os resultados para remover duplicatas
            const processedSummaries = summaries.map(summary => ({
              ...summary,
              content: removeDuplicates(summary.content)
            }));
            
            // Limpar arquivos tempor√°rios
            console.log("Limpando arquivos tempor√°rios...");
            tempFiles.forEach(tempFile => {
              try {
                if (fs.existsSync(tempFile)) {
                  fs.unlinkSync(tempFile);
                  console.log(`Arquivo tempor√°rio removido: ${tempFile}`);
                }
              } catch (cleanupError) {
                console.error(`Erro ao remover arquivo tempor√°rio ${tempFile}:`, cleanupError);
              }
            });
            
            // Limpar arquivo original
            try {
              if (fs.existsSync(filePath)) {
                fs.unlinkSync(filePath);
                console.log(`Arquivo original removido: ${filePath}`);
              }
            } catch (unlinkError) {
              console.error(`Erro ao remover arquivo original ${filePath}:`, unlinkError);
            }
            
            // Retornar resultados do OCR
            return res.json({ 
              summaries: processedSummaries,
              patientName: patientName,
              extractionMethod: extractionMethod,
              uploadMethod: 'direct',
              fileSize: fileSizeMB.toFixed(2) + 'MB',
              processingDetails: processingResults.length > 0 ? processingResults : undefined
            });
          } else {
            console.log("OCR via API n√£o retornou texto utiliz√°vel, tentando outros m√©todos");
            processingResults.push({
              method: 'ocr_api',
              success: false,
              error: 'Sem texto reconhecido'
            });
          }
        } catch (ocrError) {
          console.error("Erro no processamento OCR via API:", ocrError);
          processingResults.push({
            method: 'ocr_api',
            success: false,
            error: ocrError.message
          });
        }
      }
      
      // Se OCR falhou ou n√£o foi utilizado, continuar com fluxo normal
      
      // Processando o PDF de acordo com suas caracter√≠sticas
      if (isEncrypted && !finalText) {
        // Se o PDF estiver criptografado, tentar remover a prote√ß√£o
        console.log("PDF est√° criptografado, tentando remover prote√ß√£o...");
        const decryptResult = await attemptPdfDecryption(filePath);
        
        if (decryptResult.success) {
          console.log("Prote√ß√£o removida com sucesso, processando PDF desprotegido...");
          tempFiles.push(decryptResult.decryptedPath);
          extractionMethod = 'desprotegido';
          
          // Usar o arquivo desprotegido para os pr√≥ximos passos
          const decryptedBuffer = fs.readFileSync(decryptResult.decryptedPath);
          pdfParts = await splitPDF(decryptedBuffer);
        } else {
          console.log("N√£o foi poss√≠vel remover a prote√ß√£o, tentando reparar...");
          processingResults.push({
            method: 'desproteger',
            success: false,
            error: decryptResult.error
          });
          
          // Tentar reparar o PDF
          const repairResult = await repairPdf(filePath);
          
          if (repairResult.success) {
            console.log("PDF reparado com sucesso, processando...");
            tempFiles.push(repairResult.repairedPath);
            extractionMethod = 'reparado';
            
            // Usar o arquivo reparado para os pr√≥ximos passos
            const repairedBuffer = fs.readFileSync(repairResult.repairedPath);
            pdfParts = await splitPDF(repairedBuffer);
          } else {
            // Se n√£o conseguimos desproteger nem reparar, tentar com o arquivo original
            console.log("N√£o foi poss√≠vel reparar, tentando processar o arquivo original...");
            pdfParts = await splitPDF(pdfBuffer);
          }
        }
      } else if (!isEncrypted) {
        // Se o PDF n√£o est√° criptografado, dividir em partes normalmente
        console.log("Dividindo o PDF em partes menores...");
        pdfParts = await splitPDF(pdfBuffer);
      }
      
      // Se ainda n√£o temos um resultado final do OCR, continuamos o processamento normal
      if (!finalText) {
        // Se n√£o conseguimos dividir o PDF, usar o arquivo original como uma √∫nica parte
        if (!pdfParts || pdfParts.length === 0) {
          console.log("Falha ao dividir o PDF, usando como parte √∫nica");
          pdfParts = [pdfBuffer];
          if (extractionMethod === 'normal') {
            extractionMethod = 'falha_divisao';
          }
        } else {
          console.log(`PDF dividido em ${pdfParts.length} partes`);
        }
        
        // Extrair texto da primeira parte para obter o nome do paciente
        console.log("Extraindo informa√ß√µes do paciente...");
        const initialPages = await parsePdf(pdfParts[0]);
        
        // Usar a nova fun√ß√£o de extra√ß√£o de nome com fallback para OCR
        patientName = await extractPatientName(initialPages, filePath);
        console.log(`Nome do paciente identificado: ${patientName}`);
        
        const allSummaries = [];
        
        // Processar cada parte do PDF
        for (let i = 0; i < pdfParts.length; i++) {
          try {
            console.log(`Processando parte ${i+1}/${pdfParts.length}...`);
            const partBuffer = pdfParts[i];
            
            // Extrair texto desta parte
            const pages = await parsePdf(partBuffer);
            
            // Gerar resumos para esta parte, incluindo o nome do paciente
            const summaries = await generateSummaries(pages, patientName);
            
            // Adicionar os resumos ao array geral
            allSummaries.push(...summaries);
          } catch (partError) {
            console.error(`Erro ao processar a parte ${i+1}:`, partError);
            allSummaries.push({
              page: `Parte ${i+1}`,
              content: `Paciente: ${patientName}\n\nErro ao processar esta parte do documento.`
            });
          }
        }
        
        // Processar os resultados para remover duplicatas
        for (let i = 0; i < allSummaries.length; i++) {
          allSummaries[i].content = removeDuplicates(allSummaries[i].content);
        }
        
        // Limpar arquivos tempor√°rios
        console.log("Limpando arquivos tempor√°rios...");
        tempFiles.forEach(tempFile => {
          try {
            if (fs.existsSync(tempFile)) {
              fs.unlinkSync(tempFile);
              console.log(`Arquivo tempor√°rio removido: ${tempFile}`);
            }
          } catch (cleanupError) {
            console.error(`Erro ao remover arquivo tempor√°rio ${tempFile}:`, cleanupError);
          }
        });
        
        // Limpar arquivo original
        try {
          if (fs.existsSync(filePath)) {
            fs.unlinkSync(filePath);
            console.log(`Arquivo original removido: ${filePath}`);
          }
        } catch (unlinkError) {
          console.error(`Erro ao remover arquivo original ${filePath}:`, unlinkError);
        }
        
        // Retornar resultados
        res.json({ 
          summaries: allSummaries,
          patientName: patientName,
          extractionMethod: extractionMethod,
          uploadMethod: 'direct',
          fileSize: fileSizeMB.toFixed(2) + 'MB',
          processingDetails: processingResults.length > 0 ? processingResults : undefined
        });
      }
    } catch (processingError) {
      console.error("Erro global de processamento:", processingError);
      
      // Limpar arquivos tempor√°rios em caso de erro
      tempFiles.forEach(tempFile => {
        try {
          if (fs.existsSync(tempFile)) {
            fs.unlinkSync(tempFile);
            console.log(`Arquivo tempor√°rio removido: ${tempFile}`);
          }
        } catch (cleanupError) {
          console.error(`Erro ao remover arquivo tempor√°rio ${tempFile}:`, cleanupError);
        }
      });
      
      // Limpar arquivo original
      try {
        if (fs.existsSync(filePath)) {
          fs.unlinkSync(filePath);
          console.log(`Arquivo original removido: ${filePath}`);
        }
      } catch (unlinkError) {
        console.error(`Erro ao remover arquivo original ${filePath}:`, unlinkError);
      }
      
      // Retornar erro
      res.status(500).json({ 
        message: 'Erro ao processar o documento: ' + processingError.message,
        error: processingError.toString()
      });
    }
  } catch (error) {
    console.error('Erro ao processar o PDF:', error);
    res.status(500).json({ 
      message: 'Erro ao processar o documento: ' + error.message,
      error: error.toString()
    });
  }
});

// NOVA ROTA: Upload para arquivos grandes usando Vercel Blob
app.post('/api/upload-large', async (req, res) => {
  try {
    const { filename, fileData } = req.body;
    
    if (!filename || !fileData) {
      return res.status(400).json({ 
        message: 'Dados obrigat√≥rios: filename e fileData (base64)' 
      });
    }
    
    console.log(`Processando arquivo grande via Blob: ${filename}`);
    
    // Converter base64 de volta para buffer
    const pdfBuffer = Buffer.from(fileData, 'base64');
    const fileSizeMB = pdfBuffer.length / (1024 * 1024);
    
    console.log(`Tamanho do arquivo: ${fileSizeMB.toFixed(2)}MB`);
    
    // Validar arquivo para blob
    const validation = validatePdfForBlob(pdfBuffer, filename);
    if (!validation.valid) {
      return res.status(400).json({
        message: validation.error,
        size: validation.size + 'MB'
      });
    }
    
    try {
      // Processar usando Vercel Blob
      const results = await processLargePdfWithBlob(
        pdfBuffer, 
        filename, 
        (buffer, fname) => processPdfMain(buffer, fname)
      );
      
      console.log(`Arquivo processado com sucesso via Blob: ${filename}`);
      
      // Retornar resultados
      res.json({
        ...results,
        uploadMethod: 'blob',
        fileSize: fileSizeMB.toFixed(2) + 'MB'
      });
      
    } catch (processingError) {
      console.error("Erro no processamento via Blob:", processingError);
      res.status(500).json({ 
        message: 'Erro ao processar o documento via Blob: ' + processingError.message,
        error: processingError.toString()
      });
    }
    
  } catch (error) {
    console.error('Erro geral no upload-large:', error);
    res.status(500).json({ 
      message: 'Erro ao processar o documento: ' + error.message,
      error: error.toString()
    });
  }
});

// Handler de erro do Multer
app.use((error, req, res, next) => {
  if (error instanceof multer.MulterError) {
    if (error.code === 'LIMIT_FILE_SIZE') {
      const maxSize = isVercel ? 4 : 100;
      return res.status(413).json({
        message: `Arquivo excede o limite de ${maxSize}MB permitido`,
        error: 'FILE_TOO_LARGE',
        maxSize: maxSize + 'MB',
        suggestion: 'Use a rota /api/upload-large para arquivos maiores que 4MB'
      });
    }
  }
  
  if (error.message.includes('413')) {
    return res.status(413).json({
      message: 'Arquivo muito grande para processamento',
      error: 'PAYLOAD_TOO_LARGE',
      suggestion: 'Use a rota /api/upload-large para arquivos maiores'
    });
  }
  
  console.error('Erro n√£o tratado:', error);
  res.status(500).json({ message: 'Erro interno do servidor', error: error.message });
});

// Iniciar o servidor apenas em ambiente local
if (!isVercel) {
  app.listen(PORT, () => {
    console.log(`Servidor rodando na porta ${PORT}`);
    console.log(`Acesse: http://localhost:${PORT}`);
    console.log(`Verifica√ß√£o de sa√∫de: http://localhost:${PORT}/api/health`);
    console.log(`Blob support: ${process.env.BLOB_READ_WRITE_TOKEN ? 'Sim' : 'N√£o'}`);
  });
}

// Exportar o app para o Vercel
module.exports = app;